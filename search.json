[{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Tutorial","text":"tutorial introduce sizeSpectra package go methods estimating exponent bounded power law (\\(\\lambda\\)).","code":""},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Tutorial","text":"Size spectra (AKA Individual Size Distributions, Community Biomass Distributions) one many body-size abundance relationships. , focusing Individual Size Distributions (ISD, sensu White et al. 2007) biomass measured (estimated) every single individual within community.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"mathematical-basis","dir":"Articles","previous_headings":"Introduction","what":"Mathematical basis","title":"Tutorial","text":"distribution abundance (\\(N\\)) body size (\\(M\\)) can modeled bounded power law (Andersen et al. 2016) form: \\(\\large N \\propto M^ \\lambda\\) \\(\\lambda\\) rate parameter describing decline abundance increasing body size almost always negative. pelagic marine systems, \\(\\lambda \\approx -2\\) (Andersen Beyer 2006, Wesner et al. 2024) stream communities \\(\\lambda\\) appears \\(\\approx -1.25\\) (Pomeranz et al. 2022, Gjoni et al. 2024). negative values \\(\\lambda\\) (.e., \\(\\lambda = -2\\)) “steeper” values \\(\\lambda\\) closer 0 (.e., \\(\\lambda = -0.5\\)) “shallower”. means “steep” relationships support less biomass large body sizes, “shallow” relationships biomass larger body sizes.  commonly modeled literature creating body mass bins counting (Abundance Size Spectra) summing (Biomass size spectra) number individuals bin. bnned data log-transformed \\(\\lambda\\) estimated slope according : \\(\\large log_{10}(N) = \\lambda log_{10}(M)\\) However, binning poses number issues generally provides estimates \\(\\lambda\\) inacurate maximum likelihood methods recommended (White et al. 2008, Edwards et al. 2017, Pomeranz et al. 2024). One main issues around binning methods choice width bins, bin edges located, whether counts (sums) bin normalized (Sprules Barth 2016).","code":""},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"sizespectra-package","dir":"Articles","previous_headings":"","what":"sizeSpectra Package","title":"Tutorial","text":"Make sure sizeSpectra package downloaded. can download directly github using remotes package package downloaded, need load session: overview package can , see sizeSpectra package vignettes","code":"install.packages(\"remotes\")    # If you do not already have the \"remotes\" package remotes::install_github(\"andrew-edwards/sizeSpectra\") library(sizeSpectra)"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"data-simulation","dir":"Articles","previous_headings":"","what":"Data Simulation","title":"Tutorial","text":"Let’s start simulating vector body size data. first set seed make reproducible. code samples n = 100 body sizes power law exponent (\\(\\lambda\\)) b = -2. Becasue bounded power law, set minimum size (xmin = 1) maximum (xmax = 100). can think body size range sample fish 1 100 grams. named m2 keep track exponent used (.e., -2). Let’s sort vector view : can see body sizes less 10, large body sizes sample. Note also largest body size ~40, even though set size bounds 1 100.","code":"set.seed(598) # makes simulation reproducible m2 <- rPLB(n = 100, b = -2, xmin = 1, xmax = 100) sort(m2) ##   [1]  1.031254  1.050242  1.052482  1.068892  1.078987  1.090212  1.091879 ##   [8]  1.096940  1.097447  1.105043  1.105656  1.150811  1.170271  1.184734 ##  [15]  1.202709  1.252720  1.257296  1.329037  1.344897  1.374894  1.375970 ##  [22]  1.407335  1.424700  1.442556  1.477159  1.500558  1.510231  1.512183 ##  [29]  1.525338  1.543561  1.555712  1.567009  1.574345  1.579945  1.587565 ##  [36]  1.638134  1.663654  1.670502  1.679448  1.707943  1.714393  1.735188 ##  [43]  1.744063  1.801734  1.840380  1.852207  1.885163  1.988581  2.067230 ##  [50]  2.085163  2.097940  2.099015  2.099241  2.128986  2.135262  2.144477 ##  [57]  2.152524  2.218293  2.263141  2.502275  2.781777  2.905435  3.151122 ##  [64]  3.243437  3.352427  3.431242  3.612429  3.619371  3.757589  3.777959 ##  [71]  3.793802  3.841063  3.894318  3.957045  4.038995  4.308761  4.436295 ##  [78]  4.502082  4.634859  5.436690  5.564273  5.918682  6.008242  6.340840 ##  [85]  6.880768  6.987371  7.096980  7.183357  7.700765  8.836448 10.061311 ##  [92] 10.401013 11.740112 19.688841 23.269900 26.192331 30.367621 34.259411 ##  [99] 35.251265 39.758232"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"estimating-lambda","dir":"Articles","previous_headings":"","what":"Estimating \\(\\lambda\\)","title":"Tutorial","text":"estimate \\(\\lambda\\) vector body size data. use calcLike() function. function requires us specify negLL.fn = negLL.PLB. use one becasue continuous body size estimates individuals options details later. also need supply information data including min, max, n, sum log-transformed values. code looks like : Let’s look result: results returned list MLE estimate \\(\\lambda\\) based data. conf includes lower upper bound 95% confidence interval \\(\\lambda\\). , based data estimate \\(\\lambda = -1.87\\) 95% confidence interval : \\(-2.11, -1.65\\).","code":"mle_lambda_2 <- calcLike(       negLL.fn = negLL.PLB, # continuous estimates of all individuals       x = m2, # the vector of data       xmin = min(m2), # the minimum body size       xmax = max(m2), # the maximum body size       n = length(m2), # the number of observations       sumlogx = sum(log(m2)), # sum of log-transformed data       p = -1.5) # starting point, arbitrary number mle_lambda_2 ## $MLE ## [1] -1.871733 ##  ## $conf ## [1] -2.111733 -1.647733"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"plotting-estimates-and-data","dir":"Articles","previous_headings":"","what":"Plotting estimates and data","title":"Tutorial","text":"Edwards provides function called MLE.plot(). function requires vector body sizes MLE results.  plot x-axis log transformed.  alternative option using panel = \"h\". option displays estimate \\(\\lambda\\) figure, include confidence itnervals.","code":"MLE.plot(x = m2, # vector of simulated body sizes          b = mle_lambda_2$MLE, #lambda estimate          confVals = c(mle_lambda_2$conf[1],# confidence interval                       mle_lambda_2$conf[2]),          panel = \"b\", #This option includes the estimate and CI          log=\"xy\") # you can change this to just x MLE.plot(x = m2,           b = mle_lambda_2$MLE,           confVals = c(mle_lambda_2$conf[1],                       mle_lambda_2$conf[2]),          panel = \"b\",           log=\"x\") # Just the x axis transformed MLE.plot(x = m2, # vector of simulated body sizes          b = mle_lambda_2$MLE, #lambda estimate          panel = \"h\", #This option includes the estimate and CI          log=\"xy\") # you can also"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"practice-problems","dir":"Articles","previous_headings":"Plotting estimates and data","what":"Practice Problems","title":"Tutorial","text":"following problems, make sure use new names objects. may want add new set.seed() command simulate make results reproducible. Make two new vectors body size data change sample size , .e. n=1000 n=50. Name two new vectors m2_high_n m2_low_n. Repeat analysis just new vectors. happens estimate MLE width confidence intervals? Make one panel=\"b\" plot new results. Make two new vectors body size data n=1000 time set b = -1.5 b = -2.5 (recall b \\(\\lambda\\) controls rate decline. Name new vectors m_1.5 m_2.5. Print new vectors using sort() function. Pay special attention largest smallest body sizes sampled. often value xmin xmax observed? change “steepness” \\(\\lambda\\) value?","code":""},{"path":[]},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"working-with-real-data","dir":"Articles","previous_headings":"","what":"Working with real data","title":"Tutorial","text":"Data comes formats. show examples three common formats encounter: 1. individuals body mass estimate. 2. counts individuals given body mass. 3. Individuals “binned” broad categories body mass.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"data-format-all-indidividuals","dir":"Articles","previous_headings":"Working with real data","what":"Data format: All indidividuals","title":"Tutorial","text":"included body size observations stream sampled New Zealand. data vector \\(1,809\\) individual body sizes. Every individual measured body mass estimated using length-weight regressions. can load data following command. also print first 50 observations reference. data set body mass individuals can just plug calcLike() function . add suppress.warnings = TRUE argument well. one example, can plot results .","code":"data(\"ohc\") length(ohc) ## [1] 1809 ohc[1:50] ##  [1] 0.002960 0.008360 0.089500 0.071900 0.902721 0.115630 0.383170 4.316831 ##  [9] 0.867969 0.110412 5.223146 3.984150 0.537623 0.202904 0.081500 0.138040 ## [17] 4.783700 2.808926 0.324729 0.287618 0.284727 0.313896 0.356644 0.229078 ## [25] 0.944642 4.018426 6.076952 3.605317 0.675048 3.173486 2.651296 3.402837 ## [33] 4.201791 4.083355 3.195994 3.777321 1.932435 2.571302 0.026100 0.030900 ## [41] 1.637724 5.162719 2.702034 0.029500 0.159526 0.023000 3.184728 1.038125 ## [49] 0.055900 0.055900 mle_ohc <- calcLike(       negLL.fn = negLL.PLB,        x = ohc,        xmin = min(ohc),        xmax = max(ohc),        n = length(ohc),        sumlogx = sum(log(ohc)),        p = -1.5,       suppress.warnings = TRUE) mle_ohc ## $MLE ## [1] -1.088692 ##  ## $conf ## [1] -1.105692 -1.071692 MLE.plot(x = ohc,           b = mle_ohc$MLE,          panel = \"h\",           log=\"xy\")"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"data-format-count-of-body-sizes","dir":"Articles","previous_headings":"Working with real data","what":"Data Format: Count of body sizes","title":"Tutorial","text":"don’t always individual observation every single individual sample. example, NEON data set worked extensively collects macroinvertebrates fish different scales. order combine , calculated estimated count individuals given body size per m^2 basis. included example West St. Louis Creek Rocky Mountains Colorado. can load data following command. Notice empirical data much messier generally “fit” red line nearly nicely simulated data.","code":"data(\"WLOU\") head(WLOU) ## # A tibble: 6 × 4 ##   site_date       organism_group body_mass count_m2 ##   <chr>           <chr>              <dbl>    <dbl> ## 1 WLOU_2021-09-20 Fish                 100  0.00338 ## 2 WLOU_2021-09-20 Fish                 140  0.00314 ## 3 WLOU_2021-09-20 Fish                 180  0.00324 ## 4 WLOU_2021-09-20 Fish                 220  0.00324 ## 5 WLOU_2021-09-20 Fish                 300  0.00332 ## 6 WLOU_2021-09-20 Fish                 520  0.00298 mle_WLOU <- calcLike(       negLL.fn = negLL.PLB.counts,        x = WLOU$body_mass,       c = WLOU$count_m2,        p = -1.5,       suppress.warnings = TRUE) mle_WLOU ## $MLE ## [1] -1.54202 ##  ## $conf ## [1] -1.55102 -1.53302 MLE.plot(x = WLOU$body_mass,           b = mle_WLOU$MLE,          panel = \"h\",           log=\"xy\")"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"data-format-binned-data","dir":"Articles","previous_headings":"Working with real data","what":"Data Format: Binned data","title":"Tutorial","text":"using binned data, different function Edwards recommends plotting.","code":"data(\"fish_binned\") num.bins <- nrow(fish_binned) binBreaks <- c((fish_binned$binMin),   (fish_binned$binMax)[num.bins]) binCounts <- fish_binned$n   mle_fish_bin <- calcLike(   negLL.fn = negLL.PLB.binned,   p = -2.5,   w = binBreaks,   d = binCounts,   J = num.bins,   vecDiff = 0.5,   suppress.warnings = TRUE)  mle_fish_bin ## $MLE ## [1] -1.737086 ##  ## $conf ## [1] -1.775086 -1.700086 # LBN_bin_plot(binValsTibble = x.binned$binVals, # modify  #              b.MLE = mle_fish_bin$MLE, #              b.confMin = mle_fish_bin$conf[1], #              b.confMax = mle_fish_bin$conf[2], #              leg.text = \"(c)\", #              log.xy = \"xy\", #              plot.binned.fitted = FALSE)"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"working-with-data-from-multiple-sites","dir":"Articles","previous_headings":"","what":"Working with data from multiple sites","title":"Tutorial","text":"example, data set included package called isd_gradient. simulated data three sites across hypothetical environmental gradient. data simulated \\(\\lambda\\) three sites equal -1, -1.5, -2, respectively.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"load-the-data","dir":"Articles","previous_headings":"Working with data from multiple sites","what":"Load the data","title":"Tutorial","text":"Load data inspect . number ways treat data. One simplest (?) : 1. Split data list item list data one site. 2. Use loop estimate \\(\\lambda\\) site. 3. Store results loop data frame plotting analysis.","code":"data(\"isd_gradient\") head(isd_gradient) ##    body_mass env_value site_name ## 1  22.870249        -1    Site_A ## 2 361.130908        -1    Site_A ## 3   2.897582        -1    Site_A ## 4  97.524733        -1    Site_A ## 5   3.578355        -1    Site_A ## 6  51.687566        -1    Site_A dim(isd_gradient) ## [1] 6000    3 names(isd_gradient) ## [1] \"body_mass\" \"env_value\" \"site_name\" summary(isd_gradient) ##    body_mass         env_value   site_name         ##  Min.   :  1.000   Min.   :-1   Length:6000        ##  1st Qu.:  1.708   1st Qu.:-1   Class :character   ##  Median :  4.111   Median : 0   Mode  :character   ##  Mean   : 59.893   Mean   : 0                      ##  3rd Qu.: 23.348   3rd Qu.: 1                      ##  Max.   :990.733   Max.   : 1"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"split-the-data","dir":"Articles","previous_headings":"Working with data from multiple sites","what":"Split the data","title":"Tutorial","text":"data_list now list 3 elements , one element site.","code":"dat_list <- split(isd_gradient, isd_gradient$site_name) lapply(dat_list, head) ## $Site_A ##    body_mass env_value site_name ## 1  22.870249        -1    Site_A ## 2 361.130908        -1    Site_A ## 3   2.897582        -1    Site_A ## 4  97.524733        -1    Site_A ## 5   3.578355        -1    Site_A ## 6  51.687566        -1    Site_A ##  ## $Site_Q ##      body_mass env_value site_name ## 4001  2.427277         1    Site_Q ## 4002  4.509971         1    Site_Q ## 4003  2.391459         1    Site_Q ## 4004  7.357234         1    Site_Q ## 4005  1.337427         1    Site_Q ## 4006  4.251009         1    Site_Q ##  ## $Site_X ##      body_mass env_value site_name ## 2001 17.910886         0    Site_X ## 2002  1.999680         0    Site_X ## 2003  1.918008         0    Site_X ## 2004  1.284891         0    Site_X ## 2005  2.195040         0    Site_X ## 2006  1.692335         0    Site_X"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"for-loop","dir":"Articles","previous_headings":"Working with data from multiple sites","what":"for loop","title":"Tutorial","text":"case familiar loops, ways performing repeated set functions different sets pieces data. Generally, loop following pieces. Make empty object “catch” results. Set bounds loop. Write loop loops generally look like :","code":"dat_object <- data.frame(# empty object to catch data   col_name_1 = character(n), # name the columns and give them a class   col_name_2 = integer(n)) # use \"n\" to repeat the number of rows  for(index in 1:n){ # set the bounds. This will run through from 1:n   # body, this is where you write your code make your calculations   }"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"make-an-empty-data-frame","dir":"Articles","previous_headings":"Working with data from multiple sites > for loop","what":"Make an empty data frame","title":"Tutorial","text":"five pieces information want analysis site_name, env_value, estimated b, bounds confidence interval estimate (CI_low, CI_high). , make empty list catch results.","code":"n = length(dat_list) n ## [1] 3 isd_result <- data.frame(     site_name = character(n),     env_value = numeric(n),     b = numeric(n),      CI_low = numeric(n),     CI_high = numeric(n))  isd_result ##   site_name env_value b CI_low CI_high ## 1                   0 0      0       0 ## 2                   0 0      0       0 ## 3                   0 0      0       0"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"set-bounds-and-write-the-for-loop","dir":"Articles","previous_headings":"Working with data from multiple sites > for loop","what":"Set bounds and write the for loop","title":"Tutorial","text":"data_list three elements . use length() function set bounds loop. * use length(data_list) get value 3. * abbreviate index just letter . now three results list can easily combine single data.frame using rbind() command. Now can plot results using ggplot2 library. don’t already ggplot2, can install running following (per machine): install.packages(\"ggplot2\") can also add line best fit using stat_smooth(method = \"lm\") command.","code":"for(i in 1:n){      # read one piece of the list in at a time   dat_in <- dat_list[[i]]    # extract the relevant information from the dat_in object    body_mass <- dat_in$body_mass   site_name <- unique(dat_in$site_name)   env_value <- unique(dat_in$env_value)      mle_estimate <- calcLike(       negLL.fn = negLL.PLB,        x = body_mass,        xmin = min(body_mass),        xmax = max(body_mass),        n = length(body_mass),        sumlogx = sum(log(body_mass)),        p = -1.5,       suppress.warnings = TRUE)       # now save all the relevant information in the data frame   # Make sure to put them in the right spot         isd_result$site_name[i] = site_name   isd_result$env_value[i] = env_value   isd_result$b[i] = mle_estimate$MLE   isd_result$CI_low[i] = mle_estimate$conf[1]   isd_result$CI_high[i] = mle_estimate$conf[2]    } isd_result ##   site_name env_value         b    CI_low    CI_high ## 1    Site_A        -1 -1.012709 -1.034709 -0.9907085 ## 2    Site_Q         1 -2.003629 -2.049629 -1.9586290 ## 3    Site_X         0 -1.498724 -1.526724 -1.4707235 library(ggplot2)  ggplot(isd_result,        aes(x = env_value,            y = b,            ymin = CI_low,            ymax = CI_high)) +   geom_pointrange() ggplot(isd_result,        aes(x = env_value,            y = b,            ymin = CI_low,            ymax = CI_high)) +   geom_pointrange() +   stat_smooth(method = \"lm\")"},{"path":"https://jpomz.github.io/UFSCarISD/articles/tutorial.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Tutorial","text":"Andersen, K. H., J. E. Beyer. 2006. Asymptotic Size Determines Species Abundance Marine Size Spectrum. American Naturalist 168:54–61. Andersen, K. H., J. L. Blanchard, E. . Fulton, H. Gislason, N. S. Jacobsen, T. van Kooten. 2016. Assumptions behind size-based ecosystem models realistic. ICES Journal Marine Science 73:1651–1655. Edwards, . M. (2020). sizeSpectra: R package fitting size spectra ecological data (including binned data). https://github.com/andrew-edwards/sizeSpectra Google Scholar Edwards, . M., Robinson, J., Blanchard, J., Baum, J., & Plank, M. (2020). Accounting bin structure data removes bias fitting size spectra. Marine Ecology Progress Series, 636, 19–33. Edwards, . M., Robinson, J., Plank, M., Baum, J., & Blanchard, J. (2017). Testing recommending methods fitting size spectra data. Methods Ecology Evolution, 8, 57–67. Gjoni, V., J. P. F. Pomeranz, J. R. Junker, J. S. Wesner. 2024, January 11. Size spectra freshwater streams consistent across temperature resource supply. bioRxiv. Pomeranz, J. P. F., J. R. Junker, J. S. Wesner. 2022. Individual size distributions across North American streams vary local temperature. Global Change Biology 28:848–858. Pomeranz, J., J. R. Junker, V. Gjoni, J. S. Wesner. 2024. Maximum likelihood outperforms binning methods detecting differences abundance size spectra across environmental gradients. Journal Animal Ecology 93:267–280. Sprules, W. G., L. E. Barth. 2016. Surfing biomass size spectrum: remarks history, theory, application. Canadian Journal Fisheries Aquatic Sciences 73:477–495. White, E. P., S. K. M. Ernest, . J. Kerkhoff, B. J. Enquist. 2007. Relationships body size abundance ecology. Trends Ecology & Evolution 22:323–330. White, E. P., B. J. Enquist, J. L. Green. 2008. Estimating Exponent Power-Law Frequency Distributions. Ecology 89:905–912.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"package maintainer. Maintainer.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ww (2024). UFSCarISD: Package (Title Case). R package version 0.1.0, https://jpomz.github.io/UFSCarISD/.","code":"@Manual{,   title = {UFSCarISD: What the Package Does (Title Case)},   author = {Who wrote it},   year = {2024},   note = {R package version 0.1.0},   url = {https://jpomz.github.io/UFSCarISD/}, }"},{"path":"https://jpomz.github.io/UFSCarISD/index.html","id":"ufscarisd","dir":"","previous_headings":"","what":"What the Package Does (Title Case)","title":"What the Package Does (Title Case)","text":"goal UFSCarISD provide tutorial using sizeSpectra package Andrew Edwards. package developed order make website using pkgdown. website collection resources workshop. Workshop Details: Facilitator: Justin Pomeranz, PhD. Assistant Professor Environmental Sciences & Technology Colorado Mesa University Date: Saturday, July 6, 2024 Time: 9 5 PM Location: Integrated Research Unit Tropical Biodiversity (BIOTROP), Federal University São Carlos (UFSCar), São Carlos, São Paulo, Brazil","code":""},{"path":"https://jpomz.github.io/UFSCarISD/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"What the Package Does (Title Case)","text":"UFSCarISD package contains tutorial data objects. can install development version UFSCarISD GitHub : addition, must install sizeSpectra package using:","code":"install.packages(\"remotes\")    # If you do not already have the \"remotes\" package remotes::install_github(\"Jpomz/UFSCarISD\") remotes::install_github(\"andrew-edwards/sizeSpectra\")"},{"path":"https://jpomz.github.io/UFSCarISD/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"What the Package Does (Title Case)","text":"basic example shows data objects exist: four data sets included represent common body size data formats. ohc vector individual body sizes. individuals measured represents continuous measurement. WLOU dataframe body sizes one aquatic sites National Ecological Observatory Netwrok (NEON). data estimated count per m2 individuals given body size. fish_binned simulated data set individual fish grouped arbitrary “bins” body size data collection process. isd_gradient simulated dataset body size observations three “sites”, different individual size distribution relaitonship. used example work data multiple sites one time. Ypou can load data objects running `data(data_name). example: can learn individual data set running ?data_name. example: ’ll still need render README.Rmd regularly, keep README.md --date. devtools::build_readme() handy .","code":"library(UFSCarISD) data(package = \"UFSCarISD\") data(WLOU) ?WLOU"},{"path":"https://jpomz.github.io/UFSCarISD/reference/UFSCarISD-package.html","id":null,"dir":"Reference","previous_headings":"","what":"UFSCarISD: What the Package Does (Title Case) — UFSCarISD-package","title":"UFSCarISD: What the Package Does (Title Case) — UFSCarISD-package","text":"(maybe one line) Use four spaces indenting paragraphs within Description.","code":""},{"path":[]},{"path":"https://jpomz.github.io/UFSCarISD/reference/WLOU.html","id":null,"dir":"Reference","previous_headings":"","what":"West St. Louis Creek — WLOU","title":"West St. Louis Creek — WLOU","text":"Community data collected September 2021 West St. Louis Creek Colorado, USA. site abbreviated WLOU part National Ecological Observatory Network (NEON). information NEON can found https://www.neonscience.org/","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/WLOU.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"West St. Louis Creek — WLOU","text":"","code":"WLOU"},{"path":"https://jpomz.github.io/UFSCarISD/reference/WLOU.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"West St. Louis Creek — WLOU","text":"## `WLOU` data frame 4,558 rows 4 columns: site_date combination site name date collected organism_group Character value indicating either \"Fish\" \"Invertebrates\" body_mass Weight, mg drymass estimated individual body lengths count_m2 Estimated count individuals per meter squared scale","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/WLOU.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"West St. Louis Creek — WLOU","text":"<https://www.biorxiv.org/content/10.1101/2024.01.09.574822v1>","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/WLOU.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"West St. Louis Creek — WLOU","text":"data modified NEON data products macroinvertebrates (DP1.20120.001) fish (DP1.20107.001). collections necessarily made exact day.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/fish_binned.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated binned dataset — fish_binned","title":"Simulated binned dataset — fish_binned","text":"data simulated represent fish data recorded size \"bins\" field. , bins 5g used count fish bin tallied.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/fish_binned.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated binned dataset — fish_binned","text":"","code":"fish_binned"},{"path":"https://jpomz.github.io/UFSCarISD/reference/fish_binned.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated binned dataset — fish_binned","text":"## `fish_binned` data frame 58 rows 4 columns: binMid mid point bin binMin minimum edge bin binMax maximum edge bin n count individuals bin","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/fish_binned.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated binned dataset — fish_binned","text":"Simulated","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/isd_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data across a hypothetical gradient — isd_gradient","title":"Simulated data across a hypothetical gradient — isd_gradient","text":"data simulated represent individual size data three sites (Site , Q, X) across hypothetical environmental gradient. individual body sizes present. binning counting individuals. words, perfect example use `negLL.fn = negLL.PLB` `calcLike()` function. data simulated `sizeSpectra::rPLB()` function `b = -1`, `-1.5` `-2` respectively.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/isd_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data across a hypothetical gradient — isd_gradient","text":"","code":"isd_gradient"},{"path":"https://jpomz.github.io/UFSCarISD/reference/isd_gradient.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data across a hypothetical gradient — isd_gradient","text":"## `isd_gradient` data frame 6,000 rows 3 columns: body_mass Continuous numeric value individual body mass observation. env_value numeric value indicating hypothetical value environmental gradient. Values discrete -1, 0, 1 site_name name hypothetical site. One following: Site_A, Site_X, Site_Q","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/isd_gradient.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated data across a hypothetical gradient — isd_gradient","text":"Simulated","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/ohc.html","id":null,"dir":"Reference","previous_headings":"","what":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","title":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","text":"vector body mass (mg) observations One Horse Creek New Zealand. original study surveyed streams across acid mine drainage gradient. body sizes data aggregated three surber samples. individuals measured body mass estimated published length-weight regressions.","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/ohc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","text":"","code":"ohc"},{"path":"https://jpomz.github.io/UFSCarISD/reference/ohc.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","text":"## `ohc` vector 1,809 body size observations:","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/ohc.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","text":"<https://onlinelibrary.wiley.com/doi/abs/10.1111/fwb.13196>","code":""},{"path":"https://jpomz.github.io/UFSCarISD/reference/ohc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"One Horse Creek, New Zealand, Macroinvertebrate data — ohc","text":"work published Freshwater Biology Pomeranz et al. 2018 <https://onlinelibrary.wiley.com/doi/abs/10.1111/fwb.13196> full data set available Dryad Digital Repository: <https://doi.org/10.5061/dryad.v6g985s>","code":""}]
